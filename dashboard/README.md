# Neural Command Center Dashboard

## üöÄ Production-Grade FastAPI + React Dashboard

Enterprise-ready web dashboard for the CognitionSim cognitive architecture with:

- **Real-time cognition visualization** (Three-Plane Architecture)
- **Live training metrics streaming**
- **Governance & policy management**  
- **Edge deployment monitoring**
- **Multi-user WebSocket support**

---

## üèóÔ∏è Architecture

### Backend (FastAPI)
- **REST API** for configuration and state management
- **WebSocket** for live cognition and training streams
- **Async/await** for high performance
- **Pydantic** models for data validation
- Production-ready with **Uvicorn** ASGI server

### Frontend (React + Vite)
- **React 18** with hooks and modern patterns
- **Zustand** for lightweight state management
- **Tailwind CSS** for styling
- **Recharts** for training metrics visualization
- **Canvas API** for three-plane cognition rendering

### Deployment
- **Docker** containers for both services
- **Docker Compose** for orchestration
- **Nginx** for frontend serving and reverse proxy
- **K8s-ready** architecture

---

## üì¶ Quick Start

### Option 1: Docker (Recommended)

```bash
# One-command startup
./start_dashboard.sh

# Or manually:
cd dashboard
docker-compose up -d

# View logs
docker-compose logs -f

# Stop
docker-compose down
```

### Option 2: Development Mode

```bash
# Install and run locally
./start_dashboard_dev.sh

# Or manually:
# Terminal 1 - Backend
cd dashboard/backend
pip install -r requirements.txt
python main.py

# Terminal 2 - Frontend
cd dashboard/frontend
npm install
npm run dev
```

### Option 3: Production Build

```bash
# Build frontend
cd dashboard/frontend
npm run build

# Serve with nginx or static server
npx serve -s dist
```

---

## üéØ Features

### 1. **Cognition View** (Three-Plane Architecture)

**Plane 1: Cognitive Physiology**
- Real-time visualization of 4 cognitive layers
- Pulses, flows, pressure, and heat maps
- Activity, conflict, and pressure indicators
- Interactive canvas rendering

**Plane 2: Intent & Deliberation**
- Goal nodes with orbital dynamics
- Competing hypotheses visualization
- Click-to-pin goal prioritization
- Confidence mass distribution

**Plane 3: World Interface**
- Sensor input monitoring
- Proposed action vectors with uncertainty
- Human-in-the-loop approval system
- Action history tracking

**Interaction Panel**
- Signal injection (sensory streams)
- Cognitive probes (uncertainty, conflicts)
- Safety governors (constraints)
- No chat box - pure collaboration

### 2. **Training Dashboard**

- Live loss and metrics charts
- Learning rate visualization
- Integration with `train_live_dashboard.py`
- WebSocket streaming for real-time updates

### 3. **Governance**

- Policy management (hard/soft/contextual)
- Enable/disable enforcement
- Parameter configuration
- Audit logging ready

### 4. **Edge Deployment**

- Device status monitoring
- Inference metrics tracking
- Latency and memory usage
- Heartbeat protocol

---

## üîå API Endpoints

### REST API

```
GET  /                              - Health check
GET  /api/status                    - System status
POST /api/cognition/start           - Start cognition engine
POST /api/cognition/stop            - Stop cognition engine
GET  /api/cognition/snapshot        - Current state snapshot
POST /api/cognition/interact        - Send interaction command

GET  /api/governance/policies       - List policies
POST /api/governance/policies       - Create policy
PUT  /api/governance/policies/{id}  - Update policy
DELETE /api/governance/policies/{id} - Delete policy

GET  /api/training/metrics          - Get metrics
POST /api/training/metrics          - Add metric

GET  /api/edge/devices              - List edge devices
POST /api/edge/devices              - Register/update device
GET  /api/edge/devices/{id}         - Get device status
```

### WebSocket Endpoints

```
WS /ws/cognition  - Real-time cognition state stream
WS /ws/training   - Real-time training metrics stream
```

---

## üîß Configuration

### Backend Environment

```bash
# dashboard/backend/.env
ENVIRONMENT=production
LOG_LEVEL=info
CORS_ORIGINS=*
```

### Frontend Environment

```bash
# dashboard/frontend/.env
VITE_API_URL=http://localhost:8000
VITE_WS_URL=ws://localhost:8000
```

---

## üö¢ Deployment

### Docker Compose (Development/Testing)

```bash
docker-compose up -d
```

### Kubernetes (Production)

```bash
# Coming soon: K8s manifests in k8s/
kubectl apply -f k8s/dashboard-deployment.yml
```

### Cloud Platforms

**AWS**: ECS/EKS with ALB  
**GCP**: Cloud Run / GKE  
**Azure**: Container Instances / AKS  

---

## üìä Integrations

### Existing CognitionSim Components

‚úÖ **train_live_dashboard.py** ‚Üí `/api/training/metrics`  
‚úÖ **demo_cognition.py** ‚Üí Backend cognition engine  
‚úÖ **dashboard.html** ‚Üí Replaced with React SPA  
‚úÖ **model_monitoring.py** ‚Üí Edge device reporting  
‚úÖ **Stateful architecture** ‚Üí Persistence layer ready  

### Future Integrations

- MQTT for IoT edge devices
- Prometheus metrics export
- Grafana dashboards
- MLflow for experiment tracking

---

## üé® Customization

### Adding New Views

```jsx
// dashboard/frontend/src/views/MyView.jsx
import React from 'react';

function MyView() {
  return <div>My Custom View</div>;
}

export default MyView;
```

```jsx
// Add route in App.jsx
<Route path="/myview" element={<MyView />} />
```

### Adding Backend Endpoints

```python
# dashboard/backend/main.py
@app.get("/api/custom/endpoint")
async def custom_endpoint():
    return {"data": "custom"}
```

---

## üß™ Testing

```bash
# Backend tests
cd dashboard/backend
pytest

# Frontend tests
cd dashboard/frontend
npm test

# E2E tests
npm run test:e2e
```

---

## üìà Performance

- **WebSocket**: ~10 Hz update rate (100ms intervals)
- **API Response**: < 50ms for snapshots
- **Frontend FPS**: 60fps canvas rendering
- **Concurrent Users**: 100+ with default config

---

## üõ°Ô∏è Security

- **CORS**: Configured for production
- **Rate Limiting**: TODO (add middleware)
- **Authentication**: TODO (JWT/OAuth2)
- **HTTPS**: Required for production
- **Input Validation**: Pydantic models

---

## üìö Documentation

- **API Docs**: `http://localhost:8000/docs` (Swagger UI)
- **ReDoc**: `http://localhost:8000/redoc`
- **Frontend**: Component inline docs
- **Architecture**: See `NEURAL_COMMAND_CENTER.md`

---

## ü§ù Contributing

```bash
# Fork and clone
git clone https://github.com/yourusername/cognitionsim-a.i.

# Create feature branch
git checkout -b feature/my-feature

# Make changes and commit
git commit -am "Add my feature"

# Push and create PR
git push origin feature/my-feature
```

---

## üìù License

See root `license.md`

---

## üéØ Roadmap

- [ ] Authentication & authorization
- [ ] Multi-workspace support
- [ ] Mobile responsive design
- [ ] Dark/light theme toggle
- [ ] Export cognition sessions
- [ ] Replay mode for debugging
- [ ] Plugin system for extensions

---

## üí¨ Support

- **Issues**: GitHub Issues
- **Discussions**: GitHub Discussions
- **Email**: support@cognitionsim.ai

---

**Built with ‚ù§Ô∏è for the future of cognitive AI**
